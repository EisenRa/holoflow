configfile: "/home/projects/ku-cbd/people/nurher/holoflow/workflows/base/config.yaml"

##
# Quality-filtering
##

rule qual_filt:
    input:
        read1=expand("{inputdir}/{{sample}}_1.fastq.gz", inputdir=config['inputdir']),
        read2=expand("{inputdir}/{{sample}}_2.fastq.gz", inputdir=config['inputdir'])
    output:
        read1="{projectpath}/01-QualityFiltered/{sample}_1.fastq",
        read2="{projectpath}/01-QualityFiltered/{sample}_2.fastq",
        stats_file="{projectpath}/01-QualityFiltered/{sample}.stats"
    params:
        adapter1=expand("{adapter1}", adapter1=config['adapter1']),
        adapter2=expand("{adapter2}", adapter2=config['adapter2']),
        maxns=expand("{maxns}", maxns=config['maxns']),
        minquality=expand("{minquality}", minquality=config['minquality']),
        threads=expand("{threads}", threads=config['threads'])
    run:
        import time
        import gzip
        statsfile=open(output.stats_file,"w+")
        current_time = time.strftime("%m.%d.%y %H:%M", time.localtime())
        statsfile.write("Statistic\tValue \r\n".format(current_time))

        #Get initial stats
        reads = 0
        bases = 0
        #If gzipped
        import os
        if str(input.read1).endswith('.gz'):
            with gzip.open(str(input.read1), 'rb') as read:
                for id in read:
                    seq = next(read)
                    reads += 1
                    bases += len(seq.strip())*2
                    next(read)
                    next(read)
        else:
            with open(input.read1, 'rb') as read:
                for id in read:
                    seq = next(read)
                    reads += 1
                    bases += len(seq.strip())*2
                    next(read)
                    next(read)
        statsfile.write("Input reads\t{0} ({1} bases)\r\n".format(reads,bases))
        statsfile.close()


        shell("module unload gcc tools ngs && module load tools gcc/5.4.0 AdapterRemoval/2.1.3 && AdapterRemoval --file1 {input.read1} --file2 {input.read2} --output1 {output.read1} --output2 {output.read2} --trimqualities --trimns --maxns {params.maxns} --minquality {params.minquality} --threads {params.threads} --adapter1 {params.adapter1} --adapter2 {params.adapter2}")

        #Get stats after quality filtering
        reads = 0
        bases = 0
        with open(str(output.read1), 'rb') as read:
            for id in read:
                seq = next(read)
                reads += 1
                bases += len(seq.strip())
                next(read)
                next(read)

        #Print stats to stats file
        statsfile=open(str(output.stats_file),"a+")
        statsfile.write("Quality filtered reads\t{0} ({1} bases)\r\n".format(reads,bases))
        statsfile.close()

##
# Duplicate removal (single-based)
##

#rule dup_rem_single:
#    input:
#      read1="{projectpath}/01-QualityFiltered/{sample}_1.fastq",
#      read2="{projectpath}/01-QualityFiltered/{sample}_2.fastq"
#    output:
#      read1="{projectpath}/02-DuplicatesRemoved/{sample}_1.fastq.tmp",
#      read2="{projectpath}/02-DuplicatesRemoved/{sample}_2.fastq.tmp"
#    run:
#      shell("module load tools pigz/2.3.4 seqkit/0.7.1 && cat {input.read1} | seqkit rmdup -s -o {output.read1}")
#      shell("module load tools pigz/2.3.4 seqkit/0.7.1 && cat {input.read2} | seqkit rmdup -s -o {output.read2}")
#
#rule dup_rem_single_repair:
#    input:
#      read1="{projectpath}/02-DuplicatesRemoved/{sample}_1.fastq.tmp",
#      read2="{projectpath}/02-DuplicatesRemoved/{sample}_2.fastq.tmp"
#    output:
#      read1="{projectpath}/02-DuplicatesRemoved/{sample}_1.fastq",
#      read2="{projectpath}/02-DuplicatesRemoved/{sample}_2.fastq"
#    shell:
#      "module load tools jre/1.8.0 bbmap/36.49 && repair.sh in={input.read1} in2={input.read2} out={output.read1} out2={output.read2} overwrite=t && rm {input.read1} {input.read2}"

##
# Duplicate removal (pair-based)
##

rule dup_rem_paired:
    input:
      read1="{projectpath}/01-QualityFiltered/{sample}_1.fastq",
      read2="{projectpath}/01-QualityFiltered/{sample}_2.fastq"
    output:
      dir="{projectpath}/02-DuplicatesRemoved/{sample}.merged.fastq",
    params:
        separator=expand("{separator}", separator=config['separator'])
    shell:
      "module load tools pigz/2.3.4 seqkit/0.7.1 && paste -d {params.separator} {input.read1} {input.read2} | seqkit rmdup -s -j 28 -o {output.dir} "



rule dup_rem_paired_repair:
    input:
      in_file="{projectpath}/02-DuplicatesRemoved/{sample}.merged.fastq",
      in_stats="{projectpath}/01-QualityFiltered/{sample}.stats"
    output:
      read1="{projectpath}/02-DuplicatesRemoved/{sample}_1.fastq",
      read2="{projectpath}/02-DuplicatesRemoved/{sample}_2.fastq",
      stats_file="{projectpath}/02-DuplicatesRemoved/{sample}.stats"
    params:
        separator=expand("{separator}", separator=config['separator'])
    run:
      shell("cut --delimiter={params.separator} -f1 {input.in_file} > {output.read1}")
      shell("cut --delimiter={params.separator} -f2 {input.in_file} > {output.read2}")
      shell("rm {input.in_file}")
      shell("mv {input.in_stats} {output.stats_file}")

      #Get stats after duplicate removal
      reads = 0
      bases = 0
      with open(str(output.read1), 'rb') as read:
        for id in read:
            seq = next(read)
            reads += 1
            bases += len(seq.strip())*2
            next(read)
            next(read)

        #Print stats to stats file
        statsfile=open(str(output.stats_file),"a+")
        statsfile.write("Dereplicated reads\t{0} ({1} bases)\r\n".format(reads,bases))
        statsfile.close()



##
# Mapping to host
##

rule map_host:
    input:
        read1="{projectpath}/02-DuplicatesRemoved/{sample}_1.fastq",
        read2="{projectpath}/02-DuplicatesRemoved/{sample}_2.fastq",
        refgenome=expand("{refgenome}", refgenome=config['refgenomehost'])
    output:
        "{projectpath}/03-MappedToHost/{sample}_all.bam"
    run:
      shell("module load tools samtools/1.9 bwa/0.7.15 && bwa mem -t 28 -R '@RG\tID:ProjectName\tCN:AuthorName\tDS:Mappingt\tPL:Illumina1.9\tSM:Sample' {input.refgenome} {input.read1} {input.read2} | samtools view -T {input.refgenome} -b - > {output}")


rule map_host_split:
    input:
        refgenome=expand("{refgenomehost}", refgenomehost=config['refgenomehost']),
        all_bam="{projectpath}/03-MappedToHost/{sample}_all.bam"
    output:
        host="{projectpath}/03-MappedToHost/{sample}_host.bam",
        read1="{projectpath}/03-MappedToHost/{sample}_1.fastq",
        read2="{projectpath}/03-MappedToHost/{sample}_2.fastq"
    shell:
        """
        module load tools samtools/1.9 && samtools view -T {input.refgenome} -b -F12 {input.all_bam} > {output.host}
        module load tools samtools/1.9 && samtools view -T {input.refgenome} -b -f12 {input.all_bam} | samtools fastq -1 {output.read1} -2 {output.read2} -
        rm {input.all_bam}
        """

##
# Mapping to human
##
rule map_human:
    input:
        read1="{projectpath}/03-MappedToHost/{sample}_1.fastq",
        read2="{projectpath}/03-MappedToHost/{sample}_2.fastq",
        refgenome=expand("{refgenomehuman}", refgenomehuman=config['refgenomehuman'])
    output:
        "{projectpath}/04-MappedToHuman/{sample}_all.bam"
    run:
      shell("module load tools samtools/1.9 bwa/0.7.15 && bwa mem -t 28 -R '@RG\tID:ProjectName\tCN:AuthorName\tDS:Mappingt\tPL:Illumina1.9\tSM:Sample' {input.refgenome} {input.read1} {input.read2} | samtools view -T {input.refgenome} -b - > {output}")


rule map_human_split:
    input:
        refgenome=expand("{refgenomehuman}", refgenomehuman=config['refgenomehuman']),
        all_bam="{projectpath}/04-MappedToHuman/{sample}_all.bam",
        in_stats="{projectpath}/02-DuplicatesRemoved/{sample}.stats"
    output:
        read1="{projectpath}/04-MappedToHuman/{sample}_1.fastq", ## mapped
        read2="{projectpath}/04-MappedToHuman/{sample}_2.fastq", ## mapped
        stats_file="{projectpath}/04-MappedToHuman/{sample}.stats"
    run:
        shell("module load tools samtools/1.9 && samtools view -T {input.refgenome} -b -f12 {input.all_bam} | samtools fastq -1 {output.read1} -2 {output.read2} -")
        shell("rm {input.all_bam}")
        shell("mv {input.in_stats} {output.stats_file}")


        #Get stats
        reads = 0
        bases = 0
        with open(str(output.read1), 'rb') as read:
            for id in read:
                seq = next(read)
                reads += 1
                bases += len(seq.strip())*2
                next(read)
                next(read)
        #Print stats to statsfile
        statsfile=open(str(output.stats_file),"a+")
        statsfile.write("Reads after mapping to reference genome \t{0} ({1} bases)\r\n".format(reads,bases))
        statsfile.close()





##
# Assembly
##

rule assembly:
    input:
        read1="{projectpath}/04-MappedToHuman/{sample}_1.fastq",
        read2="{projectpath}/04-MappedToHuman/{sample}_2.fastq"
    output:
        dir=directory("{projectpath}/05-Assembly/{sample}")
    params:
        memory=expand("{memory}", memory=config['memory']),
        klist_megahit=expand("{klist_megahit}", klist_megahit=config['klist_megahit']),
        klist_spades=expand("{klist_spades}", klist_spades=config['klist_spades']),
        threads=expand("{threads}", threads=config['threads']),
        assembler=expand("{assembler}", assembler=config['assembler'])
    run:
        if params.assembler == "megahit":
            shell("module load tools megahit/1.1.1 && megahit -1 {input.read1} -2 {input.read2} -t {params.threads} --k-list {params.klist_megahit} -o {output.dir}")
        else:
            shell("module unload anaconda3/4.4.0 && module load tools anaconda3/2.1.0 spades/3.13.1 perl/5.20.2 && rm -rf {output.dir} && metaspades.py -1 {input.read1} -2 {input.read2} -t {params.threads} -m {params.memory} -k {params.klist_spades} --only-assembler -o {output.dir}")


rule assembly_move:
    input:
        dir = rules.assembly.output.dir
    output:
        final_file="{projectpath}/05-Assembly/{sample}.fa",
        stats_file="{projectpath}/05-Assembly/{sample}.stats"
    run:
        shell("mv {input.dir}/final.contigs.fa {output.final_file}")
        shell("mv {projectpath}/04-MappedToHuman/{sample}.stats {output.stats_file}")


        #Get stats after assembly
        contigs = len([1 for line in open(str(output.final_file)) if line.startswith(">")])

        #Print stats to stats file
        statsfile=open(str(output.stats_file),"a+")
        statsfile.write("Assembly contigs\t{0} \r\n".format(contigs))
        statsfile.close()
