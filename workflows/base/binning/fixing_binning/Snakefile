configfile: "/home/projects/ku-cbd/people/nurher/holoflow/workflows/base/binning/config.yaml"
import os
import glob
import shutil

##
# Index assembly
##
rule index_assembly:
    input:
        "{projectpath}/05-Assembly/{sample}/{sample}.fa"
    output: # FUTURE: ADD OPTION TO REMOVE ALL BUT FA.FAI
        samtools="{projectpath}/05-Assembly/{sample}/{sample}.fa.fai",
        bwa_bwt="{projectpath}/05-Assembly/{sample}/{sample}.fa.bwt",
        bwa_pac="{projectpath}/05-Assembly/{sample}/{sample}.fa.pac",
        bwa_ann="{projectpath}/05-Assembly/{sample}/{sample}.fa.ann",
        bwa_amb="{projectpath}/05-Assembly/{sample}/{sample}.fa.amb",
        bwa_sa="{projectpath}/05-Assembly/{sample}/{sample}.fa.sa"
    run:
        if not os.path.exists("projectpath/05-Assembly/{sample}/{sample}.fa.fai"):
            shell("module load tools samtools/1.9 && samtools faidx {input} && module load tools bwa/0.7.15 && bwa index {input}")
        else:
            pass

##
# Assembly mapping
##

rule assembly_mapping:
    input:
        assembly="{projectpath}/05-Assembly/{sample}/{sample}.fa",
        read1="{projectpath}/04-MappedToHuman/{sample}_1.fastq",
        read2="{projectpath}/04-MappedToHuman/{sample}_2.fastq"
    output:
        assemblybam="{projectpath}/06-Assembly_mapping/{sample}.mapped.bam"
    params:
        threads=expand("{threads}", threads=config['threads'])
    shell:
        """
        module load tools samtools/1.9 bwa/0.7.15 && bwa mem -t {params.threads} -R "@RG\tID:ProjectName\tCN:AuthorName\tDS:Mappingt\tPL:Illumina1.9\tSM:Sample" {input.assembly} {input.read1} {input.read2} | samtools view -T {input.assembly} -b - | samtools sort -T {input.assembly} - > {output.assemblybam}
        """

##
# Prodigal ORF prediction
##
#"Metagenomes - The simplest approach for metagenomes is to put all the sequences in one FASTA file and analyze them in Anonymous Mode."
rule protein_prediction_prodigal:
    input:
        assembly="{projectpath}/05-Assembly/{sample}/{sample}.fa"
    output:
        genetic_coords="{projectpath}/06-ProdigalPrediction/{sample}.coords.gbk",
        protein_translations="{projectpath}/06-ProdigalPrediction/{sample}.protein_translations.faa"
    shell: # Prodigal is run in "anon", Anonymous workflow
        """
        module unload gcc && module load tools prodigal/2.6.3 && prodigal -i {input.assembly} -o {output.genetic_coords} -a {output.protein_translations} -p meta
        """


configfile: "/home/projects/ku-cbd/people/nurher/holoflow/workflows/base/binning/config.yaml"
import os
import glob
import shutil

##
# Binning with metabat
##

rule binning_metabat:
    input:
        assembly_idx="{projectpath}/05-Assembly/{sample}/{sample}.fa",
        assemblybam="{projectpath}/06-Assembly_mapping/{sample}.mapped.bam"
    output:
        dir_mtb="{projectpath}/07-Binning/{sample}.metabat",
        depth_file="{projectpath}/07-Binning/{sample}.depth_metabat.txt",
        bin_table_mtb="{projectpath}/07-Binning/{sample}.bins_metabat.txt",
        final_file="{projectpath}/07-Binning/{sample}.bins_metabat.tar.gz"
    params:
        threads=expand("{threads}", threads=config['threads'])
    run:
        shell("module unload gcc && module load tools perl/5.20.2 metabat/2.12.1 && jgi_summarize_bam_contig_depths --outputDepth {output.depth_file} {input.assemblybam}")
        shell("module unload gcc && module load tools perl/5.20.2 metabat/2.12.1 && metabat2 -i {input.assembly_idx} -a {output.depth_file} -o {output.dir_mtb} -m 1500 -t {params.threads} --unbinned")

    #Create contig to bin table

        bintable = open(str(output.bin_table_mtb),"a+")

        binlist=glob.glob(str(dir_mtb+"*"))

        # metabatdir = os.path.join(projectpath,"07-Binning")
        #binlist = glob.glob(metabatdir)
        for bin in binlist:
            binname = os.path.splitext(os.path.basename(bin))[0]+''
            with open(bin, 'r') as binfile:
               for line in binfile:
                    if line.startswith('>'):
                        contig = line.strip()
                        contig = contig.replace(">", "")
                        bintable.write("{0}\t{1}\r\n".format(contig,binname))
        bintable.close()

        shell("tar -czvf {output.final_file} {output.dir_mtb}*")
##
# Binning with maxbin
##


rule binning_maxbin:
    input:
        assembly_idx="{projectpath}/05-Assembly/{sample}/{sample}.fa",
        assemblybam="{projectpath}/06-Assembly_mapping/{sample}.mapped.bam"
    output:
        dir_mxb="{projectpath}/07-Binning/{sample}.maxbin",
        depth_file="{projectpath}/07-Binning/{sample}.depth_maxbin.txt",
        bin_table_mxb="{projectpath}/07-Binning/{sample}.bins_maxbin.txt",
        final_file="{projectpath}/07-Binning/{sample}.bins_maxbin.tar.gz"
    params:
        threads=expand("{threads}", threads=config['threads'])
    run:
        shell("module unload gcc && module load tools perl/5.20.2 metabat/2.12.1 && jgi_summarize_bam_contig_depths --outputDepth {output.depth_file}--noIntraDepthVariance {input.assemblybam}")
        shell("module unload gcc && module load tools perl/5.20.2 maxbin/2.2.7 fraggenescan/1.31 && run_MaxBin.pl -contig {input.assembly_idx} -abund {output.depth_file}* -out {output.dir_mxb} -thread {params.threads}")

        #Generate bin table
        bintable = open(str(output.bin_table_mxb),"a+")

        binlist=glob.glob(str(dir_mxb+"*"))

        #maxbindir = os.path.join(output.dir_mxb + 'bin*fa*')
        #binlist = glob.glob(maxbindir)
        for bin in binlist:
            binname = os.path.splitext(os.path.basename(bin))[0]+''
            with open(bin, 'r') as binfile:
               for line in binfile:
                    if line.startswith('>'):
                        contig = line.strip()
                        contig = contig.replace(">", "")
                        bintable.write("{0}\t{1}\r\n".format(contig,binname))
        bintable.close()

        shell("tar -czvf {output.final_file} {output.dir_mxb}*")

##
# Bin refinement with DASTool using binning: metabat, maxbin and proteins from: prodigal
##
 # --proteins                 Predicted proteins in prodigal fasta format (>scaffoldID_geneNo).
 #                              Gene prediction step will be skipped if given. (optional)

rule bin_refinement:
    input:
        assembly_idx="{projectpath}/05-Assembly/{sample}/{sample}.fa",
        metabat_bintable="{projectpath}/07-Binning/{sample}.bins_metabat.txt",
        maxbin_bintable="{projectpath}/07-Binning/{sample}.bins_maxbin.txt*",
        pproteins="{projectpath}/06-ProdigalPrediction/{sample}.protein_translations.faa"
    output:
        main_dir=directory("{projectpath}/07-Binning/{sample}_BinRefinement"),
        bin_dir=directory("{projectpath}/07-Binning/{sample}_Dastool_bins")
    params:
        threads=expand("{threads}", threads=config['threads']),
        dastoolDependencies=expand("{dastoolDependencies}", dastoolDependencies=config['dastoolDependencies']),
        search_eng=expand("{search_eng}", search_eng=config['search_eng']),
        dastool_db=expand("{dastool_db}", dastool_db=config['dastool_db'])
    run:
        bincontig_tables=",".join(glob.glob({input.metabat_bintable},{input.maxbin_bintable}))
        shell("{params.dastoolDependencies} && DAS_Tool -i bincontig_tables -c {input.assembly_idx} -o {output.main_dir} --proteins {input.pproteins} -l maxbin,metabat --search_engine {params.search_eng} -t {params.threads} --db_directory {params.dastool_db} --write_bins 1")

        #Move definitive bins to a new directory /Dastool_bins
        import os
        import glob
        binsource=output.main_dir
        binfiles = glob.glob(os.path.join(binsource,'*.fa'))
        for b in binfiles:
            shutil.move(b, output.bin_dir)
